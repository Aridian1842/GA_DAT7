{
 "metadata": {
  "name": "",
  "signature": "sha256:304837975783a7bfcbd0d2398b8bffd1ae8d8f15723cd9f8f0bf5e4257cb5931"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GA Data Science 7 (DAT7) - Lab4.1\n",
      "\n",
      "### Logistic Regression and ROC Curves"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Short Version: Logistic Regression on Titanic Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import accuracy_score\n",
      "import sklearn as skl\n",
      "\n",
      "\n",
      "\n",
      "# import data\n",
      "data = pd.read_csv('data/titanic-train.csv')\n",
      "#fill na, define features and target numpy arrays\n",
      "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
      "\n",
      "#Impute the data with median values\n",
      "features_array = numerical_features.fillna(numerical_features.dropna().median()).values\n",
      "target = data.Survived.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train test split\n",
      "features_train, features_test, target_train, target_test = train_test_split(features_array, target, test_size=0.20, random_state=0)\n",
      "\n",
      "\n",
      "# train logistic regression, evaluate on test\n",
      "lr = LogisticRegression(penalty = 'l2', C=1)\n",
      "lr.fit(features_train, target_train)\n",
      "target_predicted = lr.predict(features_test)\n",
      "\n",
      "#evaluate accuracy\n",
      "print(\"\\n\\nLogistic regression of Titanic Dataset on Numerical Features\\n\\n\")\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Logistic regression of Titanic Dataset on Numerical Features\n",
        "\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.73      0.89      0.80       110\n",
        "    survived       0.73      0.48      0.58        69\n",
        "\n",
        " avg / total       0.73      0.73      0.72       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ?LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Dummy variables\n",
      "Lets do this again except we will create 3 separate columns for Pclass = 1,2,3 respectively:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DummyP = numerical_features\n",
      "\n",
      "for elem in DummyP['Pclass'].unique():\n",
      "    DummyP[str(elem)] = DummyP['Pclass'] == elem\n",
      "    \n",
      "numerical_features = numerical_features[['Fare','Pclass','Age']]\n",
      "DummyP.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>3</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td>  True</td>\n",
        "      <td> False</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "      <td> False</td>\n",
        "      <td>  True</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "      <td>  True</td>\n",
        "      <td> False</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "      <td> False</td>\n",
        "      <td>  True</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "      <td>  True</td>\n",
        "      <td> False</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "      Fare  Pclass  Age      3      1      2\n",
        "0   7.2500       3   22   True  False  False\n",
        "1  71.2833       1   38  False   True  False\n",
        "2   7.9250       3   26   True  False  False\n",
        "3  53.1000       1   35  False   True  False\n",
        "4   8.0500       3   35   True  False  False\n",
        "\n",
        "[5 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can do the same thing using the pd.get_dummies method in pandas"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "GetDummyP = numerical_features\n",
      "GetDummyP[[\"Pclass_1\",\"Pclass_2\",\"Pclass_3\",]] = pd.get_dummies(GetDummyP[\"Pclass\"])\n",
      "\n",
      "#removing Pclass as well as Pclass_2 (which is compensated by the \\beta_0 intercept value)\n",
      "#GetDummyP = GetDummyP[[\"Fare\",\"Age\",\"Pclass_1\",\"Pclass_3\"]]\n",
      "\n",
      "GetDummyP.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Pclass_1</th>\n",
        "      <th>Pclass_2</th>\n",
        "      <th>Pclass_3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "      Fare  Pclass  Age  Pclass_1  Pclass_2  Pclass_3\n",
        "0   7.2500       3   22         0         0         1\n",
        "1  71.2833       1   38         1         0         0\n",
        "2   7.9250       3   26         0         0         1\n",
        "3  53.1000       1   35         1         0         0\n",
        "4   8.0500       3   35         0         0         1\n",
        "\n",
        "[5 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array2 = GetDummyP.fillna(GetDummyP.dropna().median()).values\n",
      "features_array2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "array([[  7.25  ,   3.    ,  22.    ,   0.    ,   0.    ,   1.    ],\n",
        "       [ 71.2833,   1.    ,  38.    ,   1.    ,   0.    ,   0.    ],\n",
        "       [  7.925 ,   3.    ,  26.    ,   0.    ,   0.    ,   1.    ],\n",
        "       ..., \n",
        "       [ 23.45  ,   3.    ,  28.    ,   0.    ,   0.    ,   1.    ],\n",
        "       [ 30.    ,   1.    ,  26.    ,   1.    ,   0.    ,   0.    ],\n",
        "       [  7.75  ,   3.    ,  32.    ,   0.    ,   0.    ,   1.    ]])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train test split\n",
      "features_train, features_test, target_train, target_test = train_test_split(features_array2, target, test_size=0.20, random_state=0)\n",
      "\n",
      "\n",
      "# train logistic regression, evaluate on test\n",
      "lr = LogisticRegression(penalty = 'l2', C=1)\n",
      "lr.fit(features_train, target_train)\n",
      "target_predicted = lr.predict(features_test)\n",
      "Chi_out = skl.feature_selection.univariate_selection.chi2(features_train, target_train)\n",
      "\n",
      "#evaluate accuracy\n",
      "print(\"\\n\\nLogistic regression of Titanic Dataset on Numerical Features\\n\\n\")\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Logistic regression of Titanic Dataset on Numerical Features\n",
        "\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.73      0.85      0.79       110\n",
        "    survived       0.69      0.51      0.58        69\n",
        "\n",
        " avg / total       0.72      0.72      0.71       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"F scores\"\n",
      "print Chi_out[0]\n",
      "print \"p-values\"\n",
      "print Chi_out[1]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F scores\n",
        "[ 2958.42580967    21.06820598    31.46246907    37.49187292     4.91110755\n",
        "    28.70243028]\n",
        "p-values\n",
        "[  0.00000000e+00   4.43221494e-06   2.03332654e-08   9.17946765e-10\n",
        "   2.66845254e-02   8.43977514e-08]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observe that all all p-values are of order 10^-2 or smaller, indicating that all features are statistically significant\n",
      "\n",
      "(Note: \"F scores\" is a _statistical_ measure of the variance  of the individual features (not related to the F1 metric))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(target_test, target_predicted_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = GetDummyP.columns.values\n",
      "feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array(['Fare', 'Pclass', 'Age', 'Pclass_1', 'Pclass_2', 'Pclass_3'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(len(feature_names))\n",
      "plt.bar(x, lr.coef_.ravel())\n",
      "_ = plt.xticks(x + 0.5, feature_names, rotation=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEUCAYAAADQoHYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108ffd9d0>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Example: Logistic Regression On Titanic Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.Survived.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0    0\n",
        "1    1\n",
        "2    1\n",
        "3    1\n",
        "4    0\n",
        "Name: Survived, dtype: int64"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question: what is our prediction benchmark for model?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1 - data.Survived.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.61616161616161613"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this the subset of the full passengers list, about 2/3 perished in the event. So if we are to build a predictive model from this data, a baseline model to compare the performance to would be to always predict death. Such a constant model would reach around 62% predictive accuracy (which is higher than predicting at random):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = data.Survived.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` estimators all work with homegeneous numerical feature descriptors passed as a numpy array. Therefore passing the raw data frame will not work out of the box.\n",
      "\n",
      "Let us start simple and build a first model that only uses readily available numerical features as input, namely `data.Fare`, `data.Pclass` and `data.Age`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
      "numerical_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35\n",
        "\n",
        "[5 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately some passengers do not have age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       714\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use pandas `fillna` method to input the median age for those passengers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "median_features = numerical_features.dropna().median()\n",
      "median_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "Fare      15.7417\n",
        "Pclass     2.0000\n",
        "Age       28.0000\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features = numerical_features.fillna(median_features)\n",
      "imputed_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       891\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35\n",
        "\n",
        "[5 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the data frame is clean, we can convert it into an homogeneous numpy array of floating point values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array = imputed_features.values\n",
      "features_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "array([[  7.25  ,   3.    ,  22.    ],\n",
        "       [ 71.2833,   1.    ,  38.    ],\n",
        "       [  7.925 ,   3.    ,  26.    ],\n",
        "       ..., \n",
        "       [ 23.45  ,   3.    ,  28.    ],\n",
        "       [ 30.    ,   1.    ,  26.    ],\n",
        "       [  7.75  ,   3.    ,  32.    ]])"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take the 80% of the data for training a first model and keep 20% for computing is generalization score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "(712, 3)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "(179, 3)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "(712,)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "(179,)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a simple model from sklearn, namely `LogisticRegression`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the LR classifier and then train\n",
      "lr = LogisticRegression(C=1)\n",
      "lr.fit(features_train, target_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted = lr.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Return the accuracy\n",
      "\n",
      "accuracy_score(target_test, target_predicted)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This first model has around 73% accuracy: this is better than our baselines that always predicts death."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Model evaluation and interpretation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Interpreting linear model weights"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `coef_` attribute of a fitted linear model such as `LogisticRegression` holds the weights of each features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = numerical_features.columns.values\n",
      "feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "array(['Fare', 'Pclass', 'Age'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "array([[ 0.0043996 , -0.80916725, -0.03348064]])"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(len(feature_names))\n",
      "plt.bar(x, lr.coef_.ravel())\n",
      "_ = plt.xticks(x + 0.5, feature_names, rotation=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEJCAYAAABv6GdPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109021dd0>"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, survival is slightly positively linked with Fare (the higher the fare, the higher the likelyhood the model will predict survival) while passenger from first class and lower ages are predicted to survive more often than older people from the 3rd class.\n",
      "\n",
      "First-class cabins where closer to the lifeboats and children and women reportedly had the priority. Our model seems to capture that historical data. We will see later if the sex of the passenger can be used as an informative predictor to increase the predictive accuracy of the model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Alternative evaluation metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic Regression is a probabilistic models: instead of just predicting a binary outcome (survived or not) given the input features it can also estimates the posterior probability of the outcome given the input features using the `predict_proba` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted_proba = lr.predict_proba(features_test)\n",
      "target_predicted_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "array([[ 0.75263264,  0.24736736],\n",
        "       [ 0.75824771,  0.24175229],\n",
        "       [ 0.58542437,  0.41457563],\n",
        "       [ 0.25224882,  0.74775118],\n",
        "       [ 0.75817844,  0.24182156]])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default the decision threshold is 0.5: if we vary the decision threshold from 0 to 1 we could generate a family of binary classifier models that address all the possible trade offs between false positive and false negative prediction errors.\n",
      "\n",
      "We can summarize the performance of a binary classifier for all the possible thresholds by plotting the ROC curve and quantifying the Area under the ROC curve:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(target_test, target_predicted_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(target_test, target_predicted_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSimllFLR5f8BGMhjk754DIMAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10900dcd0>"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here the area under ROC curve is 0.756 which is very similar to the accuracy (0.732). However the ROC-AUC score of a random model is expected to 0.5 on average while the accuracy score of a random model depends on the class imbalance of the data. ROC-AUC can be seen as a way to callibrate the predictive accuracy of a model against class imbalance.\n",
      "\n",
      "It is possible to see the details of the false positive and false negative errors by computing the confusion matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "print(confusion_matrix(target_test, target_predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[98 12]\n",
        " [36 33]]\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way to quantify the quality of a binary classifier on imbalanced data is to compute the precision, recall and f1-score of a model (at the default fixed decision threshold of 0.5)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.73      0.89      0.80       110\n",
        "    survived       0.73      0.48      0.58        69\n",
        "\n",
        " avg / total       0.73      0.73      0.72       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the Docs:\n",
      "\n",
      "```python\n",
      "class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None)\u00b6\n",
      "```\n",
      "\n",
      "\n",
      "| Attributes\n",
      "|:-----------|:----------|:----------|\n",
      "| coef_ | array, shape = [n_classes-1, n_features]| Coefficient of the features in the decision function. coef_ is readonly property derived from raw_coef_ that follows the internal memory layout of liblinear.|\n",
      "| intercept_  |array, shape = [n_classes-1] | Intercept (a.k.a. bias) added to the decision function. It is available only when parameter intercept is set to True.|\n",
      "| random_state: int seed, RandomState instance, or None (default) | |The seed of the pseudo random number generator to use when shuffling the data.|\n",
      "\n",
      "\n",
      "\n",
      "| Methods\n",
      "|:-----------|:----------|\n",
      "| decision_function(X) | Predict confidence scores for samples.|\n",
      "| densify() |Convert coefficient matrix to dense array format.|\n",
      "| fit(X, y) |Fit the model according to the given training data.|\n",
      "| fit_transform(X[, y]) |Fit to data, then transform it.|\n",
      "| get_params([deep]) | Get parameters for this estimator.|\n",
      "| predict(X)  | Predict class labels for samples in X.|\n",
      "| predict_log_proba(X) | Log of probability estimates.|\n",
      "| predict_proba(X) | Probability estimates.|\n",
      "| score(X, y) |  Returns the mean accuracy on the given test data and labels.|\n",
      "| set_params(\\*\\*params) | Set the parameters of this estimator.|\n",
      "| sparsify() | Convert coefficient matrix to sparse format.|\n",
      "| transform(X[, threshold]) |Reduce X to its most important features.|"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
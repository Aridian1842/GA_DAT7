{
 "metadata": {
  "name": "",
  "signature": "sha256:5c4bf12da7574b0e7fb97d4104aeaf0ef8cd9e4ff446cade7948ebfba271c18a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GA Data Science 7 (DAT7) - Lab 5.2\n",
      "## Decision Trees\n",
      "\n",
      "ref: [http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
      "\n",
      "\n",
      "Before begining this notebook, you must install GraphViz from the following url:\n",
      "http://www.graphviz.org/Download_macos.php"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# usual imports\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "\n",
      "# previous sklearn modules\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "# decision tree classifier (new!)\n",
      "from sklearn import tree\n",
      "from sklearn.externals.six import StringIO\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "#new import (possibly)\n",
      "#!pip install pydot   #uncomment if you have not already installed\n",
      "import pydot "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Iris Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the iris dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris\n",
      "iris = load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a new pandas dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
      "df['species'] = iris.target\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a new Decision Tree classifier using default parameters:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#?tree.DecisionTreeClassifier()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit the classifier with the iris data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(df[iris.feature_names], df.species)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try graphing the tree:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"iris.dot\", 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate a png from the .dot file (must have graphviz and pydot installed):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! dot -Tpng iris.dot -o iris.png"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Show the image in our notebook:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import Image\n",
      "Image(\"iris.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now predict the classes and check the crosstabs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.predict(df[iris.feature_names])\n",
      "pd.crosstab(df.species, clf.predict(df[iris.feature_names]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Things are working, but it looks like our model is overfit, possibly due to one of these reasons:\n",
      "\n",
      "    a. The train and test datasets are the same! \n",
      "    b. We allowed a 'full' decision tree to be built.\n",
      "\n",
      "Let's run the classifier with cross validation (using the cross_val_scores helper) to address `a` and see what kind of scores we get:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      "#print an array of the (10) Cross Validation scores\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The mean of 95% is pretty good - looks like we can train a pretty good DecisionTree classifier with this data.  Is it possible we're still overfitting due to `b`?\n",
      "\n",
      "Let's look at another Decision Tree built with just a part of the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
      "clf = tree.DecisionTreeClassifier(random_state=0)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's predict classes for our test set using this simplified tree."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"iris1.dot\", 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f)\n",
      "! dot -Tpng iris1.dot -o iris1.png\n",
      "Image(\"iris1.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This tree is much simpler than the original tree based on all the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = clf.predict(X_test)\n",
      "pd.crosstab(y_test, results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that all of the class 0s were correctly predicted, and that class 0 was fully separated from class 1,2 in the tree on the first branch.  The property of X[2] - i.e. petal length <= 2.35 - is an important defining characteristic in this model.  What else can we learn about the incorrect predictions?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create new dataframes with features, species, results\n",
      "df_features = pd.DataFrame(X_test, columns=iris.feature_names)\n",
      "df_species = pd.DataFrame(y_test, columns=['species (actual)'])\n",
      "df_results = pd.DataFrame(results, columns=['species (predicted)'])\n",
      "\n",
      "# join the features, actual, and predicted into one dataframe\n",
      "df = df_features.join(df_species).join(df_results) \n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract the records where the predictions were incorrect\n",
      "df_errors = df[(df['species (actual)'] != df['species (predicted)'])]\n",
      "df_errors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trace the tree from root to leaf based to see where the rule was insufficient to correctly categorize #37, #48, and #56."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What does cross-validation look like if we use only our Train set?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Turns out the average score is actually slightly better, even though we used less data.  Maybe training with the entire dataset caused the model to be too complex - i.e. overfit?\n",
      "\n",
      "*Note: It is always good to double-check such cases, try with different random seeds, etc.  One instance often does not tell the whole story.*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Limiting Tree Depth\n",
      "\n",
      "Looking at this second model, we can see that most of the work is done in the first 3 branches - only 3 items in the training set were categorized by the 4th branch.   What happens if we limit the depth of the tree to just 3 levels?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(max_depth=3, random_state=0)\n",
      "clf.fit(X_train, y_train)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"iris2.dot\", 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f)\n",
      "! dot -Tpng iris2.dot -o iris2.png\n",
      "Image(\"iris2.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which features are most important in this classifier?  We can check by looking at the `importances`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.feature_importances_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Does limiting the max depth affect our average model performance with this training data?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Entropy vs. Gini\n",
      "\n",
      "Any difference if we use entropy instead of gini as the split criteria?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"iris3.dot\", 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f)\n",
      "! dot -Tpng iris3.dot -o iris3.png\n",
      "Image(\"iris3.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case the tree is essentially the same."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Heart Disease Dataset\n",
      "ref: [https://archive.ics.uci.edu/ml/datasets/Heart+Disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Features\n",
      "\n",
      "    Dataset has 76 total attributes - 14 attributes are used:\n",
      "    1. #3 (age)\n",
      "    2. #4 (sex)\n",
      "    3. #9 (cp)\n",
      "    4. #10 (trestbps)\n",
      "    5. #12 (chol)\n",
      "    6. #16 (fbs)\n",
      "    7. #19 (restecg)\n",
      "    8. #32 (thalach)\n",
      "    9. #38 (exang)\n",
      "    10. #40 (oldpeak)\n",
      "    11. #41 (slope)\n",
      "    12. #44 (ca)\n",
      "    13. #51 (thal)\n",
      "    14. #58 (num) (the predicted attribute) "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import the dataset into a pandas dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"data/heart_disease.csv\")\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Prepare and validate the data:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check for missing values - we've used count before:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks ok, so let's do a quick check of the means to get a sense of the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in df.columns:\n",
      "    print str(col) + ' mean: ' + str(df[col].mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hmmm ... something wrong with `ca`?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['ca'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ah!  There's a `?` character in there, and the dtype is `object`.  Note to self - always remember to check the format and validity of our data.  Based on the definition of `ca` this looks like an integer count.  It turns out that `thal` also contains some `?` values, and it looks like categorical data, so `mean()` definitely does not make sense.\n",
      "\n",
      "One interesting thing about `DecisionTrees` is that categorical data and unknown values can be ok - let's leave the `?` for now, and see what happens."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[0:5].values  # look at values for first 5 records"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like we have a mix of integers, floats, and strings.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.convert_objects(convert_numeric=True)  # convert everything to floats\n",
      "df[0:5].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That looks better, but what about the `?` values?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['thal'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['ca'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "They were converted by numpy to `nan` values.  A few notes:\n",
      "\n",
      "- a. nan is actually reasonable, since this really is missing data (and averaging doesn't make sense)\n",
      "- b. DecisionTree should technically work with NaNs (...but we will see...)\n",
      "- c. notice that the extracted values array is **a regular numpy array**, not a record array (good!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in df.columns:\n",
      "    print str(col) + ' mean: ' + str(df[col].mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Select Features and Target"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For features we want all columns except for the last one, which will be the target.  Notice that the target `num` has possible values 0, 1, 2, 3, 4, where 0 indicates absence of disease and 1-4 indicate presence.  Let's collapse 1-4 to the single value of 1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['num'] = df['num'].replace(to_replace=[2.0, 3.0, 4.0], value=1.0)\n",
      "df['num'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "#to select using column names\n",
      "features = df[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].values\n",
      "'''\n",
      "\n",
      "# to select using column indices\n",
      "\n",
      "features = df.ix[:, 0:13].values\n",
      "features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Build and fit the model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(max_depth=3, random_state=0)\n",
      "clf.fit(features, df['num'].values)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ah - turns out we do have to deal with the NaN values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's replace the 'thal' NaN with an unused value - essentially another category\n",
      "df['thal'] = df['thal'].fillna(value=1.0)\n",
      "df['thal'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's replace the 'ca' NaN with the mode of the values - i.e. the most common value\n",
      "m = df['ca'].mode()\n",
      "m[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['ca'] = df['ca'].fillna(value=m[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['ca'].values\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = df.ix[:, 0:13].values\n",
      "clf = tree.DecisionTreeClassifier(random_state=0)\n",
      "clf.fit(features, df['num'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# graph the fitted model - full dataset\n",
      "\n",
      "with open(\"heart.dot\", 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f)\n",
      "! dot -Tpng heart.dot -o heart.png\n",
      "Image(\"heart.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(clf, features, df['num'].values, cv=10)\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How important are the various features?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.feature_importances_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = clf.feature_importances_.tolist()\n",
      "x = [i for i in range(0, len(y))]\n",
      "plt.bar(x,y)\n",
      "plt.show"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Max of 5 levels"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(max_depth=5, random_state=0)\n",
      "clf.fit(features, df['num'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# graph the fitted model - full dataset, max of 5 levels\n",
      "\n",
      "with open(\"heart1.dot\", 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f)\n",
      "! dot -Tpng heart1.dot -o heart1.png\n",
      "Image(\"heart1.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(clf, features, df['num'].values, cv=10)\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## max level of 4"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(max_depth=4, random_state=0)\n",
      "clf.fit(features, df['num'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(clf, features, df['num'].values, cv=10)\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.feature_importances_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = clf.feature_importances_.tolist()\n",
      "x = [i for i in range(0, len(y))]\n",
      "plt.bar(x,y)\n",
      "plt.show"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"heart2.dot\", 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f)\n",
      "! dot -Tpng heart2.dot -o heart2.png\n",
      "Image(\"heart2.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## max level of 3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(max_depth=3, random_state=0)\n",
      "clf.fit(features, df['num'].values)\n",
      "scores = cross_val_score(clf, features, df['num'].values, cv=10)\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.feature_importances_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = clf.feature_importances_.tolist()\n",
      "x = [i for i in range(0, len(y))]\n",
      "plt.bar(x,y)\n",
      "plt.show"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"heart3.dot\", 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f)\n",
      "! dot -Tpng heart3.dot -o heart3.png\n",
      "Image(\"heart3.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Random Forests\n",
      "Random Forest will create an ensable of trees, and allow them to vote."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "?RandomForestClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf2 = RandomForestClassifier(random_state=0)\n",
      "scores = cross_val_score(clf2, features, df['num'].values, cv=10)\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets turn some of the knobs and see if it changes the result...\n",
      "clf2 = RandomForestClassifier(random_state=0, max_depth=4)\n",
      "scores = cross_val_score(clf2, features, df['num'].values, cv=10)\n",
      "print scores\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Leaf Categorization Dataset\n",
      "Optional: try the above on the Leave Catagorization set...\n",
      "ref: [https://archive.ics.uci.edu/ml/datasets/Leaf](https://archive.ics.uci.edu/ml/datasets/Leaf)\n",
      "- 1 Load the data\n",
      "- 2 Clean, format, and filter the data\n",
      "- 3 Decision tree\n",
      "    - Visualization\n",
      "- 4 Random Forest"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}